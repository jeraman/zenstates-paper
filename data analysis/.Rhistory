)
# Rename the "mean" column
datac <- rename(datac, c("mean" = measurevar))
# Add a column with 4 digits rounded measure for graphs
new_col <- paste0(measurevar,"_rnd")
datac[,new_col] <- signif(datac[,measurevar], digits=4)
datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
# Confidence interval multiplier for standard error
# Calculate t-statistic for confidence interval:
# e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
ciMult <- qt(conf.interval/2 + .5, datac$N-1)
datac$ci <- datac$se * ciMult
return(datac)
}
sh.boot <- function(data=NULL, measure, fun, iter) {
library(boot)
result = boot(data[[measure]], fun, iter)
return <- result
}
sh.histoboot <- function(data=NULL, measure, boot_results, title, bwidth = 0.5) {
library(plyr)
library(ggplot2)
#print(boot_results)
d1 = data.frame(Measure = data[[measure]])
d2 = data.frame(Measure = boot_results$t[, 1])
d1$Source = "orig"
d2$Source = "boot"
both = rbind(d1, d2)
bothmeans <- ddply(both, c("Source"), summarise, mmean = mean(Measure))
ci = boot.ci(boot_results)
histo_boot <- ggplot(both, aes(Measure, fill = Source, colour = Source)) +
geom_histogram(aes(y = ..density..), binwidth = bwidth,
alpha = 0.6, position = "identity", lwd = 0.2) +
# geom_density(color='blue', alpha=.3) +
# geom_vline(aes(xintercept = mean(Time), colour = Source),
# linetype = 'dashed', size = 0.5) +
geom_vline(data = bothmeans, aes(xintercept = mmean,
colour = Source), linetype = "dashed", size = 0.5) +
geom_vline(aes(xintercept = ci$bca[, c(4)], colour = "CI")) +
geom_vline(aes(xintercept = ci$bca[, c(5)], colour = "CI")) +
ggtitle(title) +
labs(x=measure)
print(histo_boot)
rm(d1)
rm(d2)
rm(both)
}
sh.violin <- function(data=NULL, data_sse, measure, facet=NULL, bwidth = 2.5, ylabel=NULL, gtitle="") {
library(scales)
violin <- ggplot(data = data, aes_q(x = as.name(measure))) +
#geom_violin(data= data, aes(x=Task, y=completion.time), trim=FALSE) +
geom_histogram(aes_string(y=paste("..density..*",bwidth,sep=""), fill="..density.."),
col="white", binwidth = bwidth,
alpha = .8, position = "identity", lwd = 0.2) +
scale_x_log10()
if (!is.null(facet))
violin <- violin + facet_grid(facet)
violin_b <- ggplot_build(violin)
ylab <- measure
if (!is.null(ylabel))
ylab <- ylabel
maxd <- max(violin_b$data[[1]]$density)*bwidth
violin <- violin +
geom_rect(data = data_sse, aes(xmin=CIl,ymin=0,xmax=CIh,ymax = maxd), linetype = "blank", alpha = 0.3) +
geom_segment(data = data_sse, aes_q(x=as.name(measure),y=0,xend=as.name(measure),yend = maxd), linetype = "solid", size = 0.2) +
geom_text(data=data_sse, aes(x=data_sse[[measure]],y=2*maxd/3,label = signif(data_sse[[measure]], digits=4), vjust = "left"),size=2.5,col="black") +
geom_segment(data = data_sse, aes(x=0,y=maxd,xend=+Inf,yend = maxd), linetype = "dashed", size = 0.2) +
# geom_vline(data = data_sse, aes(xintercept = CIl, colour = "CI")) +
# geom_vline(data = data_sse, aes(xintercept = CIh, colour = "CI")) +
geom_errorbarh(data = data_sse, aes_q(x = as.name(measure), y = maxd, xmin=as.name("CIl"),xmax=as.name("CIh"),height=0.005)) +
coord_flip() +
scale_color_brewer(palette="Accent") +
scale_y_continuous(labels = percent_format()) +
labs(title = gtitle, x = ylab, y = "density", fill = "density")
return(violin)
}
raw.fn_mean = function(x, indices) {
return(mean(x[indices]))
}
raw.fn_median = function(x, indices) {
return(median(x[indices]))
}
# Effect size
# Percent difference beetwen 2 measures m1,m2 are computed using
# p = 100 * (m2 - m1) / (.5 * (m1 + m2))
sh.effect_size <- function(m1,m2)
{
return(100 * (m2 - m1) / (.5 * (m1 + m2)))
}
bootstrap_and_estimation_plots <- function() {
boot_results.r <- 2000
#Bootsraping distributions for decision_speed
#All conditions
boot_results.time.all = sh.boot(raw, "decision_speed", raw.fn_mean, boot_results.r)
print(boot_results.time.all)
#sh.histoboot(raw, "decision_speed", boot_results.time.all, "All data")
#By block (i.e. technique)
boot_results.time.by_block <- list()
for (block in levels(raw$block)) {
raw.filter <- raw[raw$block == block, ]
rest <- sh.boot(raw.filter, "decision_speed", raw.fn_mean, boot_results.r)
#sh.histoboot(raw.filter, "decision_speed", rest, block)
boot_results.time.by_block[[block]] <- rest
print(rest)
}
#Bootsraping distributions for decision_accuracy
#All conditions
boot_results.acc.all = sh.boot(raw, "decision_accuracy", raw.fn_mean, boot_results.r)
print(boot_results.acc.all)
#sh.histoboot(raw, "decision_accuracy", boot_results.acc.all, "All data")
summary(raw$decision_accuracy)
summary(raw[raw$block == 'zen', ]$decision_accuracy)
summary(raw[raw$block == 'pd', ]$decision_accuracy)
summary(raw[raw$block == 'pde', ]$decision_accuracy)
#By block (i.e. technique)
boot_results.acc.by_block <- list()
for (block in levels(raw$block)) {
raw.filter <- raw[raw$block == block, ]
rest <- sh.boot(raw.filter, "decision_accuracy", raw.fn_mean, boot_results.r)
#sh.histoboot(raw.filter, "decision_accuracy", rest, block)
boot_results.acc.by_block[[block]] <- rest
print(rest)
}
#Computing 95% CIs for decision_speed
#All conditions
raw.sse.time.all <- sh.summarySE(raw, measurevar = "decision_speed")
cis = boot.ci(boot_results.time.all)
raw.sse.time.all$CIl <- cis$bca[, c(4)]
raw.sse.time.all$CIh <- cis$bca[, c(5)]
print(raw.sse.time.all)
#By block (i.e. technique)
raw.sse.time.block <- sh.summarySE(raw, measurevar = "decision_speed",
groupvars = c("block"))
raw.sse.time.block$CIl=raw.sse.time.block$ci
raw.sse.time.block$CIh=raw.sse.time.block$ci
#compute confidence intervals for each conditions in the summary using bootstrap results
for (block in levels(raw.sse.time.block$block)) {
pouet <- boot_results.time.by_block[[block]]
cis = boot.ci(pouet)
raw.sse.time.block[raw.sse.time.block$block == block, ]$CIl <- cis$bca[, c(4)]
raw.sse.time.block[raw.sse.time.block$block == block, ]$CIh <- cis$bca[, c(5)]
#print(raw.sse.time.block[raw.sse.time.block$block == block, ])
#print(cis)
}
print(raw.sse.time.block)
#Computing 95% CIs for decision_accuracy
#All conditions
raw.sse.acc.all <- sh.summarySE(raw, measurevar = "decision_accuracy")
cis = boot.ci(boot_results.acc.all)
raw.sse.acc.all$CIl <- cis$bca[, c(4)]
raw.sse.acc.all$CIh <- cis$bca[, c(5)]
print(raw.sse.acc.all)
#By block (i.e. technique)
raw.sse.acc.block <- sh.summarySE(raw, measurevar = "decision_accuracy",
groupvars = c("block"))
raw.sse.acc.block$CIl=raw.sse.acc.block$ci
raw.sse.acc.block$CIh=raw.sse.acc.block$ci
#compute confidence intervals for each conditions in the summary using bootstrap results
for (block in levels(raw.sse.acc.block$block)) {
pouet <- boot_results.acc.by_block[[block]]
cis = boot.ci(pouet)
raw.sse.acc.block[raw.sse.acc.block$block == block, ]$CIl <- cis$bca[, c(4)]
raw.sse.acc.block[raw.sse.acc.block$block == block, ]$CIh <- cis$bca[, c(5)]
#print(raw.sse.acc.block[raw.sse.acc.block$block == block, ])
#print(cis)
}
print(raw.sse.acc.block)
# Simple bargraphs with 95%CIs as error bars
dodge <- position_dodge(width = 0.9)
#Decision speed
bars.time.block <- ggplot(raw.sse.time.block, aes(x = reorder(block, decision_speed), y = decision_speed, fill = block)) +
geom_bar(stat = "identity", position = dodge) +
geom_errorbar(aes(ymin=CIl, ymax=CIh), width=.2, position=position_dodge(.9)) +
labs(x = expression(bold("Conceptual model")), y = expression(bold("Decision time (in seconds)")))
print(bars.time.block)
#Decision accuracy
bars.acc.block <- ggplot(raw.sse.acc.block, aes(x = reorder(block, decision_accuracy), y = decision_accuracy, fill = block)) +
geom_bar(stat = "identity", position = dodge) +
geom_errorbar(aes(ymin=CIl, ymax=CIh), width=.2, position=position_dodge(.9)) +
labs(x = expression(bold("Conceptual model")), y = expression(bold("Decision accuracy")))
print(bars.acc.block)
#Print distribution graphs with CIs
#All conditions
violin.time.all <- sh.violin(raw, raw.sse.time.all, measure="decision_speed", bwidth=0.15, ylabel="Completion Time (s)", gtitle="Completion Time")#bwidth=4
print(violin.time.all)
#By block (i.e. technique)
violin.time.block <- sh.violin(raw, raw.sse.time.block, measure="decision_speed", ". ~ block", bwidth=0.15, ylabel="Completion Time (s)", gtitle="Completion Time by Technique")
print(violin.time.block)
#Effect size
print("pd vs pde decision_speed effect size")
print(sh.effect_size(raw.sse.time.block[raw.sse.time.block$block == "pd", ]$decision_speed,
raw.sse.time.block[raw.sse.time.block$block == "pde", ]$decision_speed))
print("zen vs pd decision_speed effect size")
print(sh.effect_size(raw.sse.time.block[raw.sse.time.block$block == "zen", ]$decision_speed,
raw.sse.time.block[raw.sse.time.block$block == "pd", ]$decision_speed))
print("zen vs pde decision_speed effect size")
print(sh.effect_size(raw.sse.time.block[raw.sse.time.block$block == "zen", ]$decision_speed,
raw.sse.time.block[raw.sse.time.block$block == "pde", ]$decision_speed))
}
# this still have problems...
#analyzing_languages_per_id <-function () {
#getting the subarray
#    subarray = subarray_of_logins_and_anwers()
# loading the languages as a separate table
#    table_lang_id = subarray$languages
#getting unique ids
#    ids = unique(subarray$id)
# associating the ids to the languages
#    names(table_lang_id) <- subarray$id
# return results
#   return(table_lang_id)
#}
#example of how to deal with dates in r
example_on_how_to_deal_with_dates_in_r <- function () {
# converting to the proper format
dates = as.POSIXlt(raw$beginTimestamp)
# checking the array
dates
#ordering accord day and time
dates=dates[order(dates)]
# checking the ordered array
View(dates)
}
#example of how to deal with lists in R. this will be used to compute frequency in the languages
example_on_how_to_deal_with_lists_in_r_ <- function() {
# loading the profiles
raw <- stream_in(file("./profiling/user1-profiling.json"))
# loading the languages as a separate table
test = raw$languages
# associating the ids to the languages
names(test) <- raw$id
# seting the languages as factors
test=as.factor(test$id)
#showing a summary of the data
View(test)
}
#example of combining two different files into one
example_combining_different_files <- function() {
a <-loading_one_user_file("./rawdata/user1.json")
b <-loading_one_user_file("./rawdata/user3.json")
c <-loading_one_user_file("./rawdata/user4.json")
#View(a)
#View(b)
raw = rbind(a,b,c)
raw = rbind(b,c)
View(c)
}
bootstrap_and_estimation_plots()
boot_results.time.all = sh.boot(raw, "decision_speed", raw.fn_mean, boot_results.r)
print(boot_results.time.all)
boot_results.time.all = sh.boot(raw, "decision_speed", raw.fn_mean, boot_results.r)
library(boot)
library(boot)
result = boot(data[[measure]], fun, iter)
return <- result
bootstrap_and_estimation_plots()
clear
clear()
clean
boot_results.r <- 2000
boot_results.time.all = sh.boot(raw, "decision_speed", raw.fn_mean, boot_results.r)
boot_results.time.all = sh.boot(raw, "decision_speed", raw.fn_mean, boot_results.r)
boot_results.time.all = sh.boot(raw, "decision_speed", raw.fn_mean, boot_results.r)
computing_decision_speed_right_answers_boxplot_per_tool()
filenames <- list.files("./rawdata", pattern="*.json", full.names=TRUE)
filenames
raw = stream_in(file(filenames[1]))
size = length(filenames)
size
print("loading...")
for (i in 1:size) {
print(i)
print(filenames[i])
temp <- stream_in(file(filenames[i]))
#temp["decision_speed"] = temp$durationtime - temp$videotime
#temp["decision_accuracy"] = (temp$selectedanswer == temp$rightanswer)
#temp["normalized_decision_speed"] <- normalize(temp$decision_speed)
Sys.sleep(1)
if (i > 1) {
raw = rbind(raw,temp)
}
}
raw = configuring_data_types(raw)
raw = configuring_data_types(raw)
summary(raw)
View(raw)
computing_decision_speed_right_answers_boxplot_per_tool()
computing_decision_speed_all_answers_boxplot_per_tool()
computing_decision_errors_barplot_per_tool()
computing_average_completion_time()
detail_age()
detail_experience()
computing_decision_speed_barplot_with_sem_per_tool_all_answers()
detail_questionnaire()
decision_speed_anova_and_pairwise_tests()
decision_accuracy_anova_and_pairwise_tests()
bootstrap_and_estimation_plots()
bars.acc.block <- ggplot(raw.sse.acc.block, aes(x = reorder(block, decision_accuracy), y = decision_accuracy, fill = block)) +
geom_bar(stat = "identity", position = dodge) +
geom_errorbar(aes(ymin=CIl, ymax=CIh), width=.2, position=position_dodge(.9)) +
labs(x = expression(bold("Conceptual model")), y = expression(bold("Decision accuracy")), names=c("Dataflow", "Imperative", "ZenStates"))
bars.time.block <- ggplot(raw.sse.time.block, aes(x = reorder(block, decision_speed), y = decision_speed, fill = block)) +
geom_bar(stat = "identity", position = dodge) +
geom_errorbar(aes(ymin=CIl, ymax=CIh), width=.2, position=position_dodge(.9)) +
labs(x = expression(bold("Conceptual model")), y = expression(bold("Decision time (in seconds)")), names=c("Dataflow", "Imperative", "ZenStates"))
bars.time.block <- ggplot(raw.sse.time.block, aes(x = reorder(block, decision_speed), y = decision_speed, fill = block)) +
geom_bar(stat = "identity", position = dodge) +
geom_errorbar(aes(ymin=CIl, ymax=CIh), width=.2, position=position_dodge(.9)) +
labs(x = expression(bold("Conceptual model")), y = expression(bold("Decision time (in seconds)")), names=c("Dataflow", "Imperative", "ZenStates"))
for (block in levels(raw.sse.acc.block$block)) {
pouet <- boot_results.acc.by_block[[block]]
cis = boot.ci(pouet)
raw.sse.acc.block[raw.sse.acc.block$block == block, ]$CIl <- cis$bca[, c(4)]
raw.sse.acc.block[raw.sse.acc.block$block == block, ]$CIh <- cis$bca[, c(5)]
#print(raw.sse.acc.block[raw.sse.acc.block$block == block, ])
#print(cis)
}
boot_results.r <- 2000
boot_results.time.all = sh.boot(raw, "decision_speed", raw.fn_mean, boot_results.r)
print(boot_results.time.all)
boot_results.time.by_block <- list()
for (block in levels(raw$block)) {
raw.filter <- raw[raw$block == block, ]
rest <- sh.boot(raw.filter, "decision_speed", raw.fn_mean, boot_results.r)
#sh.histoboot(raw.filter, "decision_speed", rest, block)
boot_results.time.by_block[[block]] <- rest
print(rest)
}
boot_results.acc.all = sh.boot(raw, "decision_accuracy", raw.fn_mean, boot_results.r)
print(boot_results.acc.all)
summary(raw$decision_accuracy)
summary(raw[raw$block == 'zen', ]$decision_accuracy)
summary(raw[raw$block == 'pd', ]$decision_accuracy)
summary(raw[raw$block == 'pde', ]$decision_accuracy)
boot_results.acc.by_block <- list()
for (block in levels(raw$block)) {
raw.filter <- raw[raw$block == block, ]
rest <- sh.boot(raw.filter, "decision_accuracy", raw.fn_mean, boot_results.r)
#sh.histoboot(raw.filter, "decision_accuracy", rest, block)
boot_results.acc.by_block[[block]] <- rest
print(rest)
}
raw.sse.time.all <- sh.summarySE(raw, measurevar = "decision_speed")
cis = boot.ci(boot_results.time.all)
raw.sse.time.all$CIl <- cis$bca[, c(4)]
raw.sse.time.all$CIh <- cis$bca[, c(5)]
print(raw.sse.time.all)
raw.sse.time.block <- sh.summarySE(raw, measurevar = "decision_speed",
groupvars = c("block"))
raw.sse.time.block$CIl=raw.sse.time.block$ci
raw.sse.time.block$CIh=raw.sse.time.block$ci
for (block in levels(raw.sse.time.block$block)) {
pouet <- boot_results.time.by_block[[block]]
cis = boot.ci(pouet)
raw.sse.time.block[raw.sse.time.block$block == block, ]$CIl <- cis$bca[, c(4)]
raw.sse.time.block[raw.sse.time.block$block == block, ]$CIh <- cis$bca[, c(5)]
#print(raw.sse.time.block[raw.sse.time.block$block == block, ])
#print(cis)
}
print(raw.sse.time.block)
raw.sse.acc.all <- sh.summarySE(raw, measurevar = "decision_accuracy")
cis = boot.ci(boot_results.acc.all)
raw.sse.acc.all$CIl <- cis$bca[, c(4)]
raw.sse.acc.all$CIh <- cis$bca[, c(5)]
print(raw.sse.acc.all)
raw.sse.acc.block <- sh.summarySE(raw, measurevar = "decision_accuracy",
groupvars = c("block"))
raw.sse.acc.block$CIl=raw.sse.acc.block$ci
raw.sse.acc.block$CIh=raw.sse.acc.block$ci
for (block in levels(raw.sse.acc.block$block)) {
pouet <- boot_results.acc.by_block[[block]]
cis = boot.ci(pouet)
raw.sse.acc.block[raw.sse.acc.block$block == block, ]$CIl <- cis$bca[, c(4)]
raw.sse.acc.block[raw.sse.acc.block$block == block, ]$CIh <- cis$bca[, c(5)]
#print(raw.sse.acc.block[raw.sse.acc.block$block == block, ])
#print(cis)
}
print(raw.sse.acc.block)
dodge <- position_dodge(width = 0.9)
bars.time.block <- ggplot(raw.sse.time.block, aes(x = reorder(block, decision_speed), y = decision_speed, fill = block)) +
geom_bar(stat = "identity", position = dodge) +
geom_errorbar(aes(ymin=CIl, ymax=CIh), width=.2, position=position_dodge(.9)) +
labs(x = expression(bold("Conceptual model")), y = expression(bold("Decision time (in seconds)")), names=c("Dataflow", "Imperative", "ZenStates"))
bars.acc.block <- ggplot(raw.sse.acc.block, aes(x = reorder(block, decision_accuracy), y = decision_accuracy, fill = block)) +
geom_bar(stat = "identity", position = dodge) +
geom_errorbar(aes(ymin=CIl, ymax=CIh), width=.2, position=position_dodge(.9)) +
labs(x = expression(bold("Conceptual model")), y = expression(bold("Decision accuracy")))
print(bars.acc.block)
violin.time.all <- sh.violin(raw, raw.sse.time.all, measure="decision_speed", bwidth=0.15, ylabel="Completion Time (s)", gtitle="Completion Time")#bwidth=4
print(violin.time.all)
violin.time.block <- sh.violin(raw, raw.sse.time.block, measure="decision_speed", ". ~ block", bwidth=0.15, ylabel="Completion Time (s)", gtitle="Completion Time by Technique")
print(violin.time.block)
print("pd vs pde decision_speed effect size")
print(sh.effect_size(raw.sse.time.block[raw.sse.time.block$block == "pd", ]$decision_speed,
raw.sse.time.block[raw.sse.time.block$block == "pde", ]$decision_speed))
print("zen vs pd decision_speed effect size")
print(sh.effect_size(raw.sse.time.block[raw.sse.time.block$block == "zen", ]$decision_speed,
raw.sse.time.block[raw.sse.time.block$block == "pd", ]$decision_speed))
print("zen vs pde decision_speed effect size")
print(sh.effect_size(raw.sse.time.block[raw.sse.time.block$block == "zen", ]$decision_speed,
raw.sse.time.block[raw.sse.time.block$block == "pde", ]$decision_speed))
bootstrap_and_estimation_plots <- function() {
boot_results.r <- 2000
#Bootsraping distributions for decision_speed
#All conditions
boot_results.time.all = sh.boot(raw, "decision_speed", raw.fn_mean, boot_results.r)
print(boot_results.time.all)
#sh.histoboot(raw, "decision_speed", boot_results.time.all, "All data")
#By block (i.e. technique)
boot_results.time.by_block <- list()
for (block in levels(raw$block)) {
raw.filter <- raw[raw$block == block, ]
rest <- sh.boot(raw.filter, "decision_speed", raw.fn_mean, boot_results.r)
#sh.histoboot(raw.filter, "decision_speed", rest, block)
boot_results.time.by_block[[block]] <- rest
print(rest)
}
#Bootsraping distributions for decision_accuracy
#All conditions
boot_results.acc.all = sh.boot(raw, "decision_accuracy", raw.fn_mean, boot_results.r)
print(boot_results.acc.all)
#sh.histoboot(raw, "decision_accuracy", boot_results.acc.all, "All data")
summary(raw$decision_accuracy)
summary(raw[raw$block == 'zen', ]$decision_accuracy)
summary(raw[raw$block == 'pd', ]$decision_accuracy)
summary(raw[raw$block == 'pde', ]$decision_accuracy)
#By block (i.e. technique)
boot_results.acc.by_block <- list()
for (block in levels(raw$block)) {
raw.filter <- raw[raw$block == block, ]
rest <- sh.boot(raw.filter, "decision_accuracy", raw.fn_mean, boot_results.r)
#sh.histoboot(raw.filter, "decision_accuracy", rest, block)
boot_results.acc.by_block[[block]] <- rest
print(rest)
}
#Computing 95% CIs for decision_speed
#All conditions
raw.sse.time.all <- sh.summarySE(raw, measurevar = "decision_speed")
cis = boot.ci(boot_results.time.all)
raw.sse.time.all$CIl <- cis$bca[, c(4)]
raw.sse.time.all$CIh <- cis$bca[, c(5)]
print(raw.sse.time.all)
#By block (i.e. technique)
raw.sse.time.block <- sh.summarySE(raw, measurevar = "decision_speed",
groupvars = c("block"))
raw.sse.time.block$CIl=raw.sse.time.block$ci
raw.sse.time.block$CIh=raw.sse.time.block$ci
#compute confidence intervals for each conditions in the summary using bootstrap results
for (block in levels(raw.sse.time.block$block)) {
pouet <- boot_results.time.by_block[[block]]
cis = boot.ci(pouet)
raw.sse.time.block[raw.sse.time.block$block == block, ]$CIl <- cis$bca[, c(4)]
raw.sse.time.block[raw.sse.time.block$block == block, ]$CIh <- cis$bca[, c(5)]
#print(raw.sse.time.block[raw.sse.time.block$block == block, ])
#print(cis)
}
print(raw.sse.time.block)
#Computing 95% CIs for decision_accuracy
#All conditions
raw.sse.acc.all <- sh.summarySE(raw, measurevar = "decision_accuracy")
cis = boot.ci(boot_results.acc.all)
raw.sse.acc.all$CIl <- cis$bca[, c(4)]
raw.sse.acc.all$CIh <- cis$bca[, c(5)]
print(raw.sse.acc.all)
#By block (i.e. technique)
raw.sse.acc.block <- sh.summarySE(raw, measurevar = "decision_accuracy",
groupvars = c("block"))
raw.sse.acc.block$CIl=raw.sse.acc.block$ci
raw.sse.acc.block$CIh=raw.sse.acc.block$ci
#compute confidence intervals for each conditions in the summary using bootstrap results
for (block in levels(raw.sse.acc.block$block)) {
pouet <- boot_results.acc.by_block[[block]]
cis = boot.ci(pouet)
raw.sse.acc.block[raw.sse.acc.block$block == block, ]$CIl <- cis$bca[, c(4)]
raw.sse.acc.block[raw.sse.acc.block$block == block, ]$CIh <- cis$bca[, c(5)]
#print(raw.sse.acc.block[raw.sse.acc.block$block == block, ])
#print(cis)
}
print(raw.sse.acc.block)
# Simple bargraphs with 95%CIs as error bars
dodge <- position_dodge(width = 0.9)
#boxplot(decision_speed ~ block, only_right_answers, col="blue", xlab = "Conceptual model", ylab= "Decision time (in seconds)", names=c("Dataflow", "Imperative", "ZenStates"))
#Decision speed
bars.time.block <- ggplot(raw.sse.time.block, aes(x = reorder(block, decision_speed), y = decision_speed, fill = block)) +
geom_bar(stat = "identity", position = dodge) +
geom_errorbar(aes(ymin=CIl, ymax=CIh), width=.2, position=position_dodge(.9)) +
labs(x = expression(bold("Conceptual model")), y = expression(bold("Decision time (in seconds)")), names=c("Dataflow", "Imperative", "ZenStates"))
print(bars.time.block)
#Decision accuracy
bars.acc.block <- ggplot(raw.sse.acc.block, aes(x = reorder(block, decision_accuracy), y = decision_accuracy, fill = block)) +
geom_bar(stat = "identity", position = dodge) +
geom_errorbar(aes(ymin=CIl, ymax=CIh), width=.2, position=position_dodge(.9)) +
labs(x = expression(bold("Conceptual model")), y = expression(bold("Decision accuracy")))
print(bars.acc.block)
#Print distribution graphs with CIs
#All conditions
violin.time.all <- sh.violin(raw, raw.sse.time.all, measure="decision_speed", bwidth=0.15, ylabel="Completion Time (s)", gtitle="Completion Time")#bwidth=4
print(violin.time.all)
#By block (i.e. technique)
violin.time.block <- sh.violin(raw, raw.sse.time.block, measure="decision_speed", ". ~ block", bwidth=0.15, ylabel="Completion Time (s)", gtitle="Completion Time by Technique")
print(violin.time.block)
#Effect size
print("pd vs pde decision_speed effect size")
print(sh.effect_size(raw.sse.time.block[raw.sse.time.block$block == "pd", ]$decision_speed,
raw.sse.time.block[raw.sse.time.block$block == "pde", ]$decision_speed))
print("zen vs pd decision_speed effect size")
print(sh.effect_size(raw.sse.time.block[raw.sse.time.block$block == "zen", ]$decision_speed,
raw.sse.time.block[raw.sse.time.block$block == "pd", ]$decision_speed))
print("zen vs pde decision_speed effect size")
print(sh.effect_size(raw.sse.time.block[raw.sse.time.block$block == "zen", ]$decision_speed,
raw.sse.time.block[raw.sse.time.block$block == "pde", ]$decision_speed))
}
